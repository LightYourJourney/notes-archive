# 支持向量机

对于给定的样本集，分类算法的目的就是要找到一个划分超平面，将不同类别的样本分开，但能实现 这个目的的超平面可能有很多，要如何确定最好的那一个呢？图 [5.1](#_page39_x72.00_y360.02) 是一个二维的例子，可以有不同的直线 将两类样点分开。直观的看粗实线的分类效果最好，样点到直线的最短距离是最大，而且对于不同的样点

相等。

![](Aspose.Words.b353301d-f3c7-44fc-a0ef-0183eb531768.067.png)

图 5.1: 支持向量示例

支持向量机（ Support Vector Machine）就是利用这一数学特征寻找最优超平面的算法，距离超平面最 近的几个训练样本（图 [5.1](#_page39_x72.00_y360.02) 中圈出的三个点）被称为支持向量。最后找到的超平面是可只根据支持向量来 确定，因此 SVM 方法往往在样点数比较少的时候表现也很好，训练速度也比较快。

1. 支持向量机的基本型

对于样本数据集 (xi,yi),yi ∈+1 ,− 1，划分超平面可以表示为：

f (mathbfx) = wT x + b= 0 (5.1) 样本空间中任意点到该超平面的距离可以写为：

wT x + b

r = (5.2)

||w||

34

1. 支持向量机 35 如果这个超平面可以正确的对样本进行分类，可以令：

 wT i = +1; (5.3)

x + b≥ +1 , y

 wT x + b≤ − 1, yi = − 1.

其中使等号成立的样点就是支持向量，两个异类支持向量到超平面的距离和为：

2

γ = (5.4)

∥w∥

寻求最佳分割超平面的过程就是最大化 γ 的优化问题，即：

min 1∥w∥2, s.t. yi(wT xi + b) ≥ 1, i = 1 ,2,...,m (5.5)

w,b 2

利用拉格朗日乘子法可以得到这个问题的等价问题，其拉格朗日函数可以写为：

∑m

L(w,b,α) = 1∥w∥2 + α (1 − y (wT x + b)), (α ≥ 0) (5.6)

2 i i i i

i=1

令 L(w,b,α) 对 w 和 b 的偏导为零可以解出 αi 的值，同时由于约束条件为不等式， αi 还必须满足 KKT

- Karush-Kuhn-Tucker ）条件，即： 

 αi ≥ 0;

 yif (xi) − 1 ≥ 0; (5.7) 

αi(yif (xi) − 1) = 0 .

于是对于任意样本 (xi,yi)，若 αi = 0 则该样本对 f (xi) 没有影响，若 αi > 0 则必有 yif (xi) = 1，即样点 在最大间隔边界上，是一个支持向量。

2. 软间隔

如果训练样本并不是线性可分，前面介绍的算法就会失效，而缓解这一问题的一个方法就是采用 “软 间隔 ”，允许部分样本不满足约束条件 yi (wT xi + b) ≥ 1，如图 [5.2](#_page40_x72.00_y515.26) 所示，虽然在部分样本上会分类错误，但 能获得一个可行的分类方案。

![](Aspose.Words.b353301d-f3c7-44fc-a0ef-0183eb531768.068.png)

<a name="_page40_x72.00_y515.26"></a>图 5.2: 软间隔示意图

此时的优化目标为

∑m

min 1∥w∥2 + C l (y (wT x

2 0/1 i i + b) − 1) (5.8) w,b

i=1

36 第五章 支持向量机分类器

其中 l0/1 定义如下，被称为 “0/1 损失函数 ”：

l0/1 (z) =  10,, ifotherwisez < 0; . (5.9)

其中 C > 0 是一个常数，其取值越小，约束对优化目标的贡献越小，可以有更多的样点不满足约束条件，而 当 C 取值为无穷大时，优化目标等效于 “硬间隔 ”，所有样点都要满足约束条件。

然而 l0/1 函数非连续、非凸，不易进行数学分析。于是通常会用一些其他函数进行替代，常用的替代损 失函数有：

- hinge 损失：lhinge (z) = max (0,1 − z)
- 指数损失： lexp (z) = exp(− z)
- 对数损失： llog (z) = log(1 + exp(− z))
3. 核函数

对于训练样本线性不可分的情况，还可以将样本从原始空间映射到一个更高维的特征空间，使得这些 样本在新的特征空间内线性可分。数学上可以证明如果原始空间是有限维度，那么一定存在一个高维特性 空间使得样本线性可分。令 ϕ(x) 为映射函数，则变换后的模型可表示为：

f (x) = wT ϕ(x) + b (5.10) 在通过拉格朗日方程求解的过程中，会涉及到高维空间的内积计算，但由于特征空间的维数可能很高，甚

至是无穷维，直接计算内积通常很困难，因此定义如下的核函数：

κ(xi, xj ) = ⟨ϕ(xi),ϕ(xj )⟩= ϕ(xi)T ϕ(xj ) (5.11) 有了核函数就可以不必设计 ϕ() 函数，因为仅靠核函数就可以完成计算并且根据下面的定理可以更容易

的设计核函数。

令 χ 为输入空间， κ() 为定义在 χ × χ 上的对称函数，则 κ 是核函数当且仅当对于任意数据集

D = x1,..., xm ，“核矩阵 ”K 总是半正定的。 ‘

- 

κ(x1,x1) ... κ(x1,xj ) ... κ(x1,xm )

 .. ... ... .. .. 

K = κ(xi., x1) κ(xi, xj ) . . 

 ... ...... ... ...... κ(xi,...xm )  (5.12)

κ(xm ,x1) ... κ(xm ,xj ) ... κ(xm ,xm )

常用的核函数有如下几个：

- 线性核 κ(xi,xj ) = xTi xj
- 多项式核 κ(xi,xj ) = (xTi x )d
- 高斯核 κ(xi,xj ) = exp(− ∥jxi2−σ,x2d∥2≥)，1σ为多项式的次数> 0 为高斯核的带宽 j
- 拉普拉斯核 κ(xi,xj ) = exp(− ∥xi −σxj ∥2 )，σ > 0
- Sigmoid 核 κ(xi,xj ) = tanh(βxTi xj + θ)