4. 卷积神经网络（<a name="_page77_x72.00_y72.00"></a> **CNN**）模型

CNN 相比多层感知机等简单神经网络的特点是：一，连接仅与图像相邻像素相对应的神经元，让神经 元处理来自彼此接近的像素的信息，比如为了识别字母或数字，需要分析像素的相关性，它们决定了元素 的形状；二，使用共享参数，一层中所有神经元之间共享有限数量的权重，由此减少了权重数量，有助于防 止过拟合。

1. 卷积层

卷积层是 CNN 的重要组成部分，由一组过滤器（ Filters，也称为卷积核，或特征检测器）组成，每个过 滤器都应用于输入数据的所有区域。过滤器由一组可学习的权重定义。如图 [8.5](#_page77_x72.00_y337.47)所示，每个输入神经元可以 代表一个像素的灰度值，首先，在图像的右上角应用 3x3 过滤器（通常大小是任意的，如 2x2、4x4、5x5 等）， 由于有九个输入神经元相连，就有 9 个权重，过滤器的输出是其输入的加权和。过滤器的输出表示下一层 神经元的激活值，如果对应于该过滤器的特征出现在该处，则下一层相应的神经元将激活，神经元之后使 用激活函数，最常见的激活函数是 ReLU。对于下一层的每个新的神经元，过滤器将在输入图像上移动，然 后用每组新的输入神经元计算其输出。对于移动，过滤器的权重在整个图像中不会改变（权重共享），即使

用所有相同的 9 个过滤器权重计算所有输出神经元的激活，每次使用一组不同的输入神经元。每个过滤器 对应于特定的一个特征，通过共享权重，可保证过滤器能够在整个图像中找到特征。

![](Aspose.Words.b353301d-f3c7-44fc-a0ef-0183eb531768.113.png)

<a name="_page77_x72.00_y337.47"></a>图 8.5: 过滤器及其在图像上的移动

在空间上排列的神经元称为深度切片（ Depth Slices）或特征图（ Feature Map），切片可以用作网络中 其他层的输入。在卷积层，偏置权重也在所有神经元之间共享，对整个切片使用单个偏置权重。对于彩色 图片，可以将图像分成多个颜色通道，若为 RGB 图像，则为 3，将每个颜色通道视为一个深度切片，切片的 组合称为深度为 3 的输入体积（ Input Volume）。如图 [8.6所示，](#_page78_x72.00_y64.23)唯一的 3x3 过滤器应用于每个切片，将这三 个过滤器组合成一个 3x3x3+1（含一个偏置）的大过滤器，有 28 个权重。

一个过滤器对应于一个特定特征，如边或线，而许多特征都很重要，故一组输入切片上可以应用多个 过滤器，每个过滤器将生成一个唯一的输出切片。

输入和输出特征映射具有不同的维度，假设有一个大小为（ width, height）的输入层和一个维度为

- filter\_w, filter\_h）的过滤器，应用卷积后，输出层的维度为（ width-filter\_w+1, height-filter\_h+1），如

图 [8.7](#_page78_x72.00_y215.30)所示。

设计一个 CNN，需要做的是定义网络架构，如卷积层的数量、输出体积的深度以及过滤器的大小，经 训练后网络将找出特征。

过滤器不仅可以每次移动一个像素，也可以移动多个像素，卷积层的这个参数称为步幅（步长），而通 常输入的所有维度的步幅都是相同的。把步幅包括进去，输出层的维度为（ (width-filter\_w)/stride\_w+1, (height-filter\_h)/stride\_h+1）。例如，一个 28x28 输入图像，使用步幅为 1 的 3x3 过滤器卷积生成的正方


4. 卷积神经网络（ CNN）模型 73

![](Aspose.Words.b353301d-f3c7-44fc-a0ef-0183eb531768.114.png)

<a name="_page78_x72.00_y64.23"></a>图 8.6: 深度为 3 的输入切片示例

![](Aspose.Words.b353301d-f3c7-44fc-a0ef-0183eb531768.115.png)

<a name="_page78_x72.00_y215.30"></a>图 8.7: 在 4x4 切片上使用 2x2 过滤器进行卷积的示例

形切片输出大小为 28-3+1=26，但是当步长为 2 时，得到 (28-3)/2+1=13。较大步幅的主要作用是增加输 出神经元的感受野，使网络能够检测到输入的更大、更复杂的特征。

如果需要使输出的幅度与输入相同，可以在卷积运算之前用 0 的行和列填充输入片的边缘，如图 [8.8](#_page78_x72.00_y494.84)所 示。加入填充这个因素，假设输入切片为 I = (Iw,Ih )，过滤器为 F = (Fw,Fh )，步幅为 S = (Sw,Sh )，填充

为 P = (Pw,Ph )，则输出切片 O = (Ow,Oh ) 由以下公式给出：

O = Iw + 2 Pw − Fw + 1

w S

w

O = Ih + 2 Ph − Fh + 1

h Sh

![](Aspose.Words.b353301d-f3c7-44fc-a0ef-0183eb531768.116.png)

<a name="_page78_x72.00_y494.84"></a>图 8.8: 对卷积层进行填充以使得输出与输入幅度相同

2. 池化层

借助池化层（ Pooling Layers）也可以增加神经元的感受野。池化层将输入切片分割成一个网格，每个 网格单元代表一个由多个神经元组成的感受野。然后在网格的每个单元上应用池化操作。池化层不会改 变体积深度，因为池化操作是在每个切片上独立执行的。

最常用的最大池化会在每个局部感受野（网格单元）中获取具有最高激活值的神经元。感受野为 2x2 的最大池化如图 [8.9](#_page79_x72.00_y102.83)所示。平均池化则输出每个感受野内所有激活的平均值。池化层涉及两个参数，步幅

（与卷积层相同）及感受野大小，实际上只使用两种组合，第一种是 2x2 的感受野，步幅为 2；第二种是 3x3

的感受野，步幅为 2（重叠）。

![](Aspose.Words.b353301d-f3c7-44fc-a0ef-0183eb531768.117.png)

<a name="_page79_x72.00_y102.83"></a>图 8.9: 最大池化示例

用 I 表示输入切片的大小，用 F 表示感受野的大小，用 S 表示步幅的大小，用 O 表示输出的大小，池 化层通常没有填充，其输出大小计算公式如下：

O = Iw + 2 Pw − Fw + 1

w Sw

- Ih + 2 Ph − Fh + 1

Oh Sh

3. 卷积神经网络的结构

![](Aspose.Words.b353301d-f3c7-44fc-a0ef-0183eb531768.118.png)

<a name="_page79_x72.00_y361.78"></a>图 8.10: 卷积神经网络的结构

一个基本 CNN 的结构如图 [8.10](#_page79_x72.00_y361.78)所示。大多数 CNN 有如下基本属性：

1. 通常将一个或多个卷积层与一个池化层交替使用，由此卷积层可以在感受野大小的每一级检测特征。 较深层的感受野大小大于网络起始处的感受野大小，由此可以从较大的输入区域捕获更复杂的特征。
1. 最深层检测到的特征是高度抽象的，无法直接阅读，通常在最后一个卷积 /池化层之后添加一个或多 个全连接层。可以将全连接层视为网络语言（人类无法理解）和人类语言之间的翻译器。
1. 较深的卷积层通常比初始层存在更多的过滤器（因此体积深度更高）。网络开始时的特征检测器工作 在一个小的感受野上，只能检测在所有类之间共享的有限数量的特征，如边或线。而一个较深的层将 检测到更复杂和众多的特征，比如汽车、树或人，每个类都有自己的一组特征，如轮胎、车门、树叶和 脸等，因此需要更多的特征检测器。
